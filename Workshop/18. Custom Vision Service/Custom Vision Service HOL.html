<!DOCTYPE html>
<html>
<head>
<title>Custom Vision Service HOL</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<style type="text/css">
/* GitHub stylesheet for MarkdownPad (http://markdownpad.com) */
/* Author: Nicolas Hery - http://nicolashery.com */
/* Version: b13fe65ca28d2e568c6ed5d7f06581183df8f2ff */
/* Source: https://github.com/nicolahery/markdownpad-github */

/* RESET
=============================================================================*/

html, body, div, span, applet, object, iframe, h1, h2, h3, h4, h5, h6, p, blockquote, pre, a, abbr, acronym, address, big, cite, code, del, dfn, em, img, ins, kbd, q, s, samp, small, strike, strong, sub, sup, tt, var, b, u, i, center, dl, dt, dd, ol, ul, li, fieldset, form, label, legend, table, caption, tbody, tfoot, thead, tr, th, td, article, aside, canvas, details, embed, figure, figcaption, footer, header, hgroup, menu, nav, output, ruby, section, summary, time, mark, audio, video {
  margin: 0;
  padding: 0;
  border: 0;
}

/* BODY
=============================================================================*/

body {
  font-family: Helvetica, arial, freesans, clean, sans-serif;
  font-size: 14px;
  line-height: 1.6;
  color: #333;
  background-color: #fff;
  padding: 20px;
  max-width: 960px;
  margin: 0 auto;
}

body>*:first-child {
  margin-top: 0 !important;
}

body>*:last-child {
  margin-bottom: 0 !important;
}

/* BLOCKS
=============================================================================*/

p, blockquote, ul, ol, dl, table, pre {
  margin: 15px 0;
}

/* HEADERS
=============================================================================*/

h1, h2, h3, h4, h5, h6 {
  margin: 20px 0 10px;
  padding: 0;
  font-weight: bold;
  -webkit-font-smoothing: antialiased;
}

h1 tt, h1 code, h2 tt, h2 code, h3 tt, h3 code, h4 tt, h4 code, h5 tt, h5 code, h6 tt, h6 code {
  font-size: inherit;
}

h1 {
  font-size: 28px;
  color: #000;
}

h2 {
  font-size: 24px;
  border-bottom: 1px solid #ccc;
  color: #000;
}

h3 {
  font-size: 18px;
}

h4 {
  font-size: 16px;
}

h5 {
  font-size: 14px;
}

h6 {
  color: #777;
  font-size: 14px;
}

body>h2:first-child, body>h1:first-child, body>h1:first-child+h2, body>h3:first-child, body>h4:first-child, body>h5:first-child, body>h6:first-child {
  margin-top: 0;
  padding-top: 0;
}

a:first-child h1, a:first-child h2, a:first-child h3, a:first-child h4, a:first-child h5, a:first-child h6 {
  margin-top: 0;
  padding-top: 0;
}

h1+p, h2+p, h3+p, h4+p, h5+p, h6+p {
  margin-top: 10px;
}

/* LINKS
=============================================================================*/

a {
  color: #4183C4;
  text-decoration: none;
}

a:hover {
  text-decoration: underline;
}

/* LISTS
=============================================================================*/

ul, ol {
  padding-left: 30px;
}

ul li > :first-child, 
ol li > :first-child, 
ul li ul:first-of-type, 
ol li ol:first-of-type, 
ul li ol:first-of-type, 
ol li ul:first-of-type {
  margin-top: 0px;
}

ul ul, ul ol, ol ol, ol ul {
  margin-bottom: 0;
}

dl {
  padding: 0;
}

dl dt {
  font-size: 14px;
  font-weight: bold;
  font-style: italic;
  padding: 0;
  margin: 15px 0 5px;
}

dl dt:first-child {
  padding: 0;
}

dl dt>:first-child {
  margin-top: 0px;
}

dl dt>:last-child {
  margin-bottom: 0px;
}

dl dd {
  margin: 0 0 15px;
  padding: 0 15px;
}

dl dd>:first-child {
  margin-top: 0px;
}

dl dd>:last-child {
  margin-bottom: 0px;
}

/* CODE
=============================================================================*/

pre, code, tt {
  font-size: 12px;
  font-family: Consolas, "Liberation Mono", Courier, monospace;
}

code, tt {
  margin: 0 0px;
  padding: 0px 0px;
  white-space: nowrap;
  border: 1px solid #eaeaea;
  background-color: #f8f8f8;
  border-radius: 3px;
}

pre>code {
  margin: 0;
  padding: 0;
  white-space: pre;
  border: none;
  background: transparent;
}

pre {
  background-color: #f8f8f8;
  border: 1px solid #ccc;
  font-size: 13px;
  line-height: 19px;
  overflow: auto;
  padding: 6px 10px;
  border-radius: 3px;
}

pre code, pre tt {
  background-color: transparent;
  border: none;
}

kbd {
    -moz-border-bottom-colors: none;
    -moz-border-left-colors: none;
    -moz-border-right-colors: none;
    -moz-border-top-colors: none;
    background-color: #DDDDDD;
    background-image: linear-gradient(#F1F1F1, #DDDDDD);
    background-repeat: repeat-x;
    border-color: #DDDDDD #CCCCCC #CCCCCC #DDDDDD;
    border-image: none;
    border-radius: 2px 2px 2px 2px;
    border-style: solid;
    border-width: 1px;
    font-family: "Helvetica Neue",Helvetica,Arial,sans-serif;
    line-height: 10px;
    padding: 1px 4px;
}

/* QUOTES
=============================================================================*/

blockquote {
  border-left: 4px solid #DDD;
  padding: 0 15px;
  color: #777;
}

blockquote>:first-child {
  margin-top: 0px;
}

blockquote>:last-child {
  margin-bottom: 0px;
}

/* HORIZONTAL RULES
=============================================================================*/

hr {
  clear: both;
  margin: 15px 0;
  height: 0px;
  overflow: hidden;
  border: none;
  background: transparent;
  border-bottom: 4px solid #ddd;
  padding: 0;
}

/* TABLES
=============================================================================*/

table th {
  font-weight: bold;
}

table th, table td {
  border: 1px solid #ccc;
  padding: 6px 13px;
}

table tr {
  border-top: 1px solid #ccc;
  background-color: #fff;
}

table tr:nth-child(2n) {
  background-color: #f8f8f8;
}

/* IMAGES
=============================================================================*/

img {
  max-width: 100%
}
</style>
<style type="text/css">
.highlight  { background: #ffffff; }
.highlight .c { color: #999988; font-style: italic } /* Comment */
.highlight .err { color: #a61717; background-color: #e3d2d2 } /* Error */
.highlight .k { font-weight: bold } /* Keyword */
.highlight .o { font-weight: bold } /* Operator */
.highlight .cm { color: #999988; font-style: italic } /* Comment.Multiline */
.highlight .cp { color: #999999; font-weight: bold } /* Comment.Preproc */
.highlight .c1 { color: #999988; font-style: italic } /* Comment.Single */
.highlight .cs { color: #999999; font-weight: bold; font-style: italic } /* Comment.Special */
.highlight .gd { color: #000000; background-color: #ffdddd } /* Generic.Deleted */
.highlight .gd .x { color: #000000; background-color: #ffaaaa } /* Generic.Deleted.Specific */
.highlight .ge { font-style: italic } /* Generic.Emph */
.highlight .gr { color: #aa0000 } /* Generic.Error */
.highlight .gh { color: #999999 } /* Generic.Heading */
.highlight .gi { color: #000000; background-color: #ddffdd } /* Generic.Inserted */
.highlight .gi .x { color: #000000; background-color: #aaffaa } /* Generic.Inserted.Specific */
.highlight .go { color: #888888 } /* Generic.Output */
.highlight .gp { color: #555555 } /* Generic.Prompt */
.highlight .gs { font-weight: bold } /* Generic.Strong */
.highlight .gu { color: #aaaaaa } /* Generic.Subheading */
.highlight .gt { color: #aa0000 } /* Generic.Traceback */
.highlight .kc { font-weight: bold } /* Keyword.Constant */
.highlight .kd { font-weight: bold } /* Keyword.Declaration */
.highlight .kp { font-weight: bold } /* Keyword.Pseudo */
.highlight .kr { font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: #445588; font-weight: bold } /* Keyword.Type */
.highlight .m { color: #009999 } /* Literal.Number */
.highlight .s { color: #d14 } /* Literal.String */
.highlight .na { color: #008080 } /* Name.Attribute */
.highlight .nb { color: #0086B3 } /* Name.Builtin */
.highlight .nc { color: #445588; font-weight: bold } /* Name.Class */
.highlight .no { color: #008080 } /* Name.Constant */
.highlight .ni { color: #800080 } /* Name.Entity */
.highlight .ne { color: #990000; font-weight: bold } /* Name.Exception */
.highlight .nf { color: #990000; font-weight: bold } /* Name.Function */
.highlight .nn { color: #555555 } /* Name.Namespace */
.highlight .nt { color: #000080 } /* Name.Tag */
.highlight .nv { color: #008080 } /* Name.Variable */
.highlight .ow { font-weight: bold } /* Operator.Word */
.highlight .w { color: #bbbbbb } /* Text.Whitespace */
.highlight .mf { color: #009999 } /* Literal.Number.Float */
.highlight .mh { color: #009999 } /* Literal.Number.Hex */
.highlight .mi { color: #009999 } /* Literal.Number.Integer */
.highlight .mo { color: #009999 } /* Literal.Number.Oct */
.highlight .sb { color: #d14 } /* Literal.String.Backtick */
.highlight .sc { color: #d14 } /* Literal.String.Char */
.highlight .sd { color: #d14 } /* Literal.String.Doc */
.highlight .s2 { color: #d14 } /* Literal.String.Double */
.highlight .se { color: #d14 } /* Literal.String.Escape */
.highlight .sh { color: #d14 } /* Literal.String.Heredoc */
.highlight .si { color: #d14 } /* Literal.String.Interpol */
.highlight .sx { color: #d14 } /* Literal.String.Other */
.highlight .sr { color: #009926 } /* Literal.String.Regex */
.highlight .s1 { color: #d14 } /* Literal.String.Single */
.highlight .ss { color: #990073 } /* Literal.String.Symbol */
.highlight .bp { color: #999999 } /* Name.Builtin.Pseudo */
.highlight .vc { color: #008080 } /* Name.Variable.Class */
.highlight .vg { color: #008080 } /* Name.Variable.Global */
.highlight .vi { color: #008080 } /* Name.Variable.Instance */
.highlight .il { color: #009999 } /* Literal.Number.Integer.Long */
.pl-c {
    color: #969896;
}

.pl-c1,.pl-mdh,.pl-mm,.pl-mp,.pl-mr,.pl-s1 .pl-v,.pl-s3,.pl-sc,.pl-sv {
    color: #0086b3;
}

.pl-e,.pl-en {
    color: #795da3;
}

.pl-s1 .pl-s2,.pl-smi,.pl-smp,.pl-stj,.pl-vo,.pl-vpf {
    color: #333;
}

.pl-ent {
    color: #63a35c;
}

.pl-k,.pl-s,.pl-st {
    color: #a71d5d;
}

.pl-pds,.pl-s1,.pl-s1 .pl-pse .pl-s2,.pl-sr,.pl-sr .pl-cce,.pl-sr .pl-sra,.pl-sr .pl-sre,.pl-src,.pl-v {
    color: #df5000;
}

.pl-id {
    color: #b52a1d;
}

.pl-ii {
    background-color: #b52a1d;
    color: #f8f8f8;
}

.pl-sr .pl-cce {
    color: #63a35c;
    font-weight: bold;
}

.pl-ml {
    color: #693a17;
}

.pl-mh,.pl-mh .pl-en,.pl-ms {
    color: #1d3e81;
    font-weight: bold;
}

.pl-mq {
    color: #008080;
}

.pl-mi {
    color: #333;
    font-style: italic;
}

.pl-mb {
    color: #333;
    font-weight: bold;
}

.pl-md,.pl-mdhf {
    background-color: #ffecec;
    color: #bd2c00;
}

.pl-mdht,.pl-mi1 {
    background-color: #eaffea;
    color: #55a532;
}

.pl-mdr {
    color: #795da3;
    font-weight: bold;
}

.pl-mo {
    color: #1d3e81;
}
.task-list {
padding-left:10px;
margin-bottom:0;
}

.task-list li {
    margin-left: 20px;
}

.task-list-item {
list-style-type:none;
padding-left:10px;
}

.task-list-item label {
font-weight:400;
}

.task-list-item.enabled label {
cursor:pointer;
}

.task-list-item+.task-list-item {
margin-top:3px;
}

.task-list-item-checkbox {
display:inline-block;
margin-left:-20px;
margin-right:3px;
vertical-align:1px;
}
</style>
</head>
<body>
<p><a name="HOLTitle"></a></p>
<h1>Using the Microsoft Custom Vision Service to Perform Image Classification</h1>
<hr>
<p><a name="Overview"></a></p>
<h2>Overview</h2>
<p><a href="https://azure.microsoft.com/en-us/services/cognitive-services/" title="Microsoft Cognitive Services" rel="nofollow">Microsoft Cognitive Services</a> is a suite of services and APIs backed by machine learning that enables developers to incorporate intelligent features such as facial recognition in photos and videos, sentiment analysis in text, and language understanding into their applications. Microsoft's <a href="https://azure.microsoft.com/en-us/services/cognitive-services/custom-vision-service/" rel="nofollow">Custom Vision Service</a> is among the newest members of the Cognitive Services suite. Its purpose is to create image classification models that "learn" from labeled images you provide. Want to know if a photo contains a picture of a flower? Train the Custom Vision Service with a collection of flower images, and it can tell you whether the next image includes a flower — or even what type of flower it is.</p>
<p><a href="Images/custom-vision-details.jpg" target="_blank"><img src="Images/custom-vision-details.jpg" alt="" style="max-width:100%;"></a></p>
<p>The Custom Vision Service enables organizations to develop domain-specific image-classification models and use it to analyze image content. Examples include identifying a dog's breed from a picture of the dog, analyzing images for adult content, and identifying defective parts produced by manufacturing processes. It was recently used to <a href="https://blogs.technet.microsoft.com/canitpro/2017/05/10/teaching-drones-to-aid-search-and-rescue-efforts-via-cognitive-services/" rel="nofollow">help search-and-rescue drones</a> identify objects such as boats and life vests in large bodies of water and recognize potential emergency situations in order to notify a rescue squad without waiting for human intervention.</p>
<p>The Custom Vision Service exposes two APIs: the <a href="https://southcentralus.dev.cognitive.microsoft.com/docs/services/d9a10a4a5f8549599f1ecafc435119fa/operations/58d5835bc8cb231380095be3" rel="nofollow">Custom Vision Training API</a> and the <a href="https://southcentralus.dev.cognitive.microsoft.com/docs/services/eb68250e4e954d9bae0c2650db79c653/operations/58acd3c1ef062f0344a42814" rel="nofollow">Custom Vision Prediction API</a>. You can build, train, and test image-classification models using the <a href="https://www.customvision.ai/" rel="nofollow">Custom Vision Service portal</a>, or you can build, train, and test them using the Custom Vision Training API. Once a model is trained, you can use the Custom Vision Prediction API to build apps that utilize it. Both are REST APIs that are easily called from a variety of programming languages.</p>
<p>In this lab, you will create a Custom Vision Service model, train it with images of famous paintings tagged with the artists' names, and utilize the model from a Node.js app to identify the artist of paintings that you upload. Along the way, you will learn how to train a Custom Vision Service model and leverage it from your apps using REST APIs.</p>
<p><a name="Objectives"></a></p>
<h3>Objectives</h3>
<p>In this hands-on lab, you will learn how to:</p>
<ul>
<li>Create a Custom Vision Service project</li>
<li>Train a Custom Vision Service model with tagged images</li>
<li>Test a Custom Vision Service model</li>
<li>Create apps that leverage Custom Vision Service models by calling REST APIs</li>
</ul>
<p><a name="Prerequisites"></a></p>
<h3>Prerequisites</h3>
<p>The following are required to complete this hands-on lab:</p>
<ul>
<li>A Microsoft account. If you don't have one, <a href="https://account.microsoft.com/account" rel="nofollow">sign up for free</a>.</li>
<li>Microsoft <a href="http://code.visualstudio.com" rel="nofollow">Visual Studio Code</a> version 1.14.0 or higher</li>
<li><a href="https://nodejs.org" rel="nofollow">Node.js</a> version 6.0 or higher</li>
</ul>
<p><a name="Resources"></a></p>
<h3>Resources</h3>
<p><a href="https://a4r.blob.core.windows.net/public/cvs-resources.zip" rel="nofollow">Click here</a> to download a zip file containing the resources used in this lab. Copy the contents of the zip file into a folder on your hard disk.</p>
<hr>
<p><a name="Exercises"></a></p>
<h2>Exercises</h2>
<p>This hands-on lab includes the following exercises:</p>
<ul>
<li><a href="#Exercise1">Exercise 1: Create a Custom Vision Service project</a></li>
<li><a href="#Exercise2">Exercise 2: Upload tagged images</a></li>
<li><a href="#Exercise3">Exercise 3: Train the model</a></li>
<li><a href="#Exercise4">Exercise 4: Test the model</a></li>
<li><a href="#Exercise5">Exercise 5: Create a Node.js app that uses the model</a></li>
<li><a href="#Exercise6">Exercise 6: Use the app to classify images</a></li>
</ul>
<p>Estimated time to complete this lab: <strong>45</strong> minutes.</p>
<p><a name="Exercise1"></a></p>
<h2>Exercise 1: Create a Custom Vision Service project</h2>
<p>The first step in building an image-classification model with the Custom Vision Service is to create a project. In this exercise, you will use the Custom Vision Service portal to create a Custom Vision Service project.</p>
<ol>
<li>
<p>Open the <a href="https://www.customvision.ai/" rel="nofollow">Custom Vision Service portal</a> in your browser. Then click <strong>Sign In</strong>.</p>
<p><a href="Images/portal-sign-in.png" target="_blank"><img src="Images/portal-sign-in.png" alt="Signing in to the Custom Vision Service portal" style="max-width:100%;"></a></p>
<p><em>Signing in to the Custom Vision Service portal</em></p>
</li>
<li>
<p>If you are asked to sign in, do so using the credentials for your Microsoft account. If you are asked to let this app access your info, click <strong>Yes</strong>, and if prompted, agree to the terms of service.</p>
</li>
<li>
<p>Click <strong>New Project</strong> to create a new project.</p>
<p><a href="Images/portal-click-new-project.png" target="_blank"><img src="Images/portal-click-new-project.png" alt="Creating a Custom Vision Service project" style="max-width:100%;"></a></p>
<p><em>Creating a Custom Vision Service project</em></p>
</li>
<li>
<p>In the "New project" dialog, name the project "Artworks," ensure that <strong>General</strong> is selected as the domain, and click <strong>Create project</strong>.</p>
<blockquote>
<p>A domain optimizes a model for specific types of images. For example, if your goal is to classify food images by the types of food they contain or the ethnicity of the dishes, then it might be helpful to select the Food domain. For scenarios that don't match any of the offered domains, or if you are unsure of which domain to choose, select the General domain.</p>
</blockquote>
<p><a href="Images/portal-create-project.png" target="_blank"><img src="Images/portal-create-project.png" alt="Creating a Custom Vision Service project" style="max-width:100%;"></a></p>
<p><em>Creating a Custom Vision Service project</em></p>
</li>
</ol>
<p>The next step is to upload images to the project and assign tags to those images to classify them.</p>
<p><a name="Exercise2"></a></p>
<h2>Exercise 2: Upload tagged images</h2>
<p>In this exercise, you will add images of famous paintings by Picasso, Pollock, and Rembrandt to the Artworks project, and tag the images so the Custom Vision Service can learn to differentiate one artist from another.</p>
<ol>
<li>
<p>Click <strong>Add images</strong> to add images to the project.</p>
<p><a href="Images/portal-click-add-images.png" target="_blank"><img src="Images/portal-click-add-images.png" alt="Adding images to the Artworks project" style="max-width:100%;"></a></p>
<p><em>Adding images to the Artworks project</em></p>
</li>
<li>
<p>Click <strong>Browse local files</strong>.</p>
<p><a href="Images/portal-click-browse-local-files.png" target="_blank"><img src="Images/portal-click-browse-local-files.png" alt="Browsing for local images" style="max-width:100%;"></a></p>
<p><em>Browsing for local images</em></p>
</li>
<li>
<p>Browse to the "Artists\Picasso" folder in the <a href="https://a4r.blob.core.windows.net/public/cvs-resources.zip" rel="nofollow">resources that accompany this lab</a>, select all of the files in the folder, and click <strong>Open</strong>.</p>
<p><a href="Images/fe-browse-picasso-01.png" target="_blank"><img src="Images/fe-browse-picasso-01.png" alt="Selecting an image" style="max-width:100%;"></a></p>
<p><em>Selecting an image</em></p>
</li>
<li>
<p>Type "painting" (without quotation marks) into the <strong>Add some tags...</strong> box. Then click <strong>+</strong> to assign the tag to the images.</p>
<p><a href="Images/portal-add-tags-01.png" target="_blank"><img src="Images/portal-add-tags-01.png" alt="Adding a &quot;painting&quot; tag to the images" style="max-width:100%;"></a></p>
<p><em>Adding a "painting" tag to the images</em></p>
</li>
<li>
<p>Repeat Step 4 to add a "Picasso" tag to the images.</p>
</li>
<li>
<p>Click <strong>Upload 7 files</strong> to upload the images. Once the upload has completed, click <strong>Done</strong>.</p>
<p><a href="Images/upload-picasso-images.png" target="_blank"><img src="Images/upload-picasso-images.png" alt="Uploading tagged images" style="max-width:100%;"></a></p>
<p><em>Uploading tagged images</em></p>
</li>
<li>
<p>Confirm that the images you uploaded appear in the portal, along with the tags assigned to them.</p>
<p><a href="Images/portal-tagged-01.png" target="_blank"><img src="Images/portal-tagged-01.png" alt="The uploaded images" style="max-width:100%;"></a></p>
<p><em>The uploaded images</em></p>
</li>
<li>
<p>With seven Picasso images, the Custom Vision Service can do a decent job of identifying paintings by Picasso. But if you trained the model right now, it would only understand what a Picasso looks like, and it would not be able to identify paintings by other artists.</p>
<p>The next step is to upload some paintings by another artist. Click <strong>Add images</strong> and select all of the images in the "Artists\Rembrandt" folder in the lab resources. Tag them with the labels "painting" and "Rembrandt" (not "Picasso"), and upload them to the project.</p>
<blockquote>
<p>When you add the tag "painting," you don't have to type it in again. You can select it from the drop-down list attached to the <strong>Add some tags...</strong> box, as shown below. You <strong>will</strong> have to type "Rembrandt" and click <strong>+</strong> to add a "Rembrandt" tag.</p>
</blockquote>
<p><a href="Images/select-painting-tag.png" target="_blank"><img src="Images/select-painting-tag.png" alt="Selecting an existing tag" style="max-width:100%;"></a></p>
<p><em>Selecting an existing tag</em></p>
</li>
<li>
<p>Confirm that the Rembrandt images appear alongside the Picasso images in the project, and that "Rembrandt" appears in the list of tags.</p>
<p><a href="Images/portal-tagged-02.png" target="_blank"><img src="Images/portal-tagged-02.png" alt="Picasso and Rembrandt images" style="max-width:100%;"></a></p>
<p><em>Picasso and Rembrandt images</em></p>
</li>
<li>
<p>Now add paintings by the enigmatic artist Jackson Pollock to enable the Custom Vision Service to recognize Pollock paintings, too. Select all of the images in the "Artists\Pollock" folder in the lab resources, tag them with the terms "painting" and "Pollock", and upload them to the project.</p>
</li>
</ol>
<p>With the tagged images uploaded, the next step is to train the model with these images so it can distinguish between paintings by Picasso, Rembrandt, and Pollock, as well as determine whether a painting is a work by one of these famous artists.</p>
<p><a name="Exercise3"></a></p>
<h2>Exercise 3: Train the model</h2>
<p>In this exercise, you will train the model using the images uploaded and tagged in the previous exercise. Training can be accomplished with a simple button click in the portal, or by calling the <a href="https://southcentralus.dev.cognitive.microsoft.com/docs/services/d9a10a4a5f8549599f1ecafc435119fa/operations/58d5835bc8cb231380095bed" rel="nofollow">TrainProject</a> method in the <a href="https://southcentralus.dev.cognitive.microsoft.com/docs/services/d9a10a4a5f8549599f1ecafc435119fa/operations/58d5835bc8cb231380095be3" rel="nofollow">Custom Vision Training API</a>. Once trained, a model can be refined by uploading additional tagged images and retraining it.</p>
<ol>
<li>
<p>Click the <strong>Train</strong> button at the top of the page to train the model. Each time you train the model, a new iteration is created. The Custom Vision Service maintains several iterations, allowing you to compare your progress over time.</p>
<p><a href="Images/portal-click-train.png" target="_blank"><img src="Images/portal-click-train.png" alt="Training the model" style="max-width:100%;"></a></p>
<p><em>Training the model</em></p>
</li>
<li>
<p>Wait for the training process to complete. (It should only take a few seconds.) Then review the training statistics presented to you for iteration 1. <strong>Precision</strong> and <strong>recall</strong> are separate but related  measures of the model's accuracy. Suppose the model was presented with three Picassos and three Van Goghs, and that it correctly identified two of the Picassos as "Picasso" images, but incorrectly identified two of the Van Goghs as Picassos. In this case, the precision would be 50% (two of the four images it classified as Picassos are actually Picassos), while its recall would be 67% (it correctly identified two of the three Picasso images as Picassos). You can learn more about precision and recall from <a href="https://en.wikipedia.org/wiki/Precision_and_recall" rel="nofollow">https://en.wikipedia.org/wiki/Precision_and_recall</a>.</p>
<p><a href="Images/portal-train-complete.png" target="_blank"><img src="Images/portal-train-complete.png" alt="Results of training the model" style="max-width:100%;"></a></p>
<p><em>Results of training the model</em></p>
</li>
</ol>
<p>Now let's test the model using the portal's Quick Test feature, which allows you to submit images to the model and see how it classifies them using the knowledge gained from the training images.</p>
<p><a name="Exercise4"></a></p>
<h2>Exercise 4: Test the model</h2>
<p>In <a href="#Exercise5">Exercise 5</a>, you will create a Node.js app that uses the model to identify the artist of paintings presented to it. But you don't have to write an app to test the model; you can do your testing in the portal, and you can further refine the model using the images that you test with. In this exercise, you will test the model's ability to identify the artist of a painting using test images provided for you.</p>
<ol>
<li>
<p>Click <strong>Quick Test</strong> at the top of the page.</p>
<p><a href="Images/portal-click-quick-test.png" target="_blank"><img src="Images/portal-click-quick-test.png" alt="Testing the model" style="max-width:100%;"></a></p>
<p><em>Testing the model</em></p>
</li>
<li>
<p>Click <strong>Browse local files</strong>, and then browse to the "Quick Tests" folder in the lab resources. Select <strong>PicassoTest_01.jpg</strong>, and click <strong>Open</strong>.</p>
<p><a href="Images/portal-select-test-01.png" target="_blank"><img src="Images/portal-select-test-01.png" alt="Selecting a Picasso test image" style="max-width:100%;"></a></p>
<p><em>Selecting a Picasso test image</em></p>
</li>
<li>
<p>Examine the results of the test in the "Quick Test" dialog. What is the probability that the painting is a Picasso? What is the probability that it is a Rembrandt or Pollock?</p>
</li>
<li>
<p>Close the "Quick Test" dialog. Then click <strong>Predictions</strong> at the top of the page.</p>
<p><a href="Images/portal-select-predictions.png" target="_blank"><img src="Images/portal-select-predictions.png" alt="Viewing the tests that have been performed" style="max-width:100%;"></a></p>
<p><em>Viewing the tests that have been performed</em></p>
</li>
<li>
<p>Click the test image that you uploaded to show a detail of it. Then tag the image as a "Picasso" by selecting <strong>Picasso</strong> from the drop-down list and clicking <strong>Save and close</strong>.</p>
<blockquote>
<p>By tagging test images this way, you can refine the model without uploading additional training images.</p>
</blockquote>
<p><a href="Images/tag-test-image.png" target="_blank"><img src="Images/tag-test-image.png" alt="Tagging the test image" style="max-width:100%;"></a></p>
<p><em>Tagging the test image</em></p>
</li>
<li>
<p>Perform another quick test using the file named <strong>FlowersTest.jpg</strong> in the "Quick Test" folder. Confirm that this image is assigned a low probability of being a Picasso, a Rembrandt, or a Pollock.</p>
</li>
</ol>
<p>The model is trained and ready to go and appears to be adept at identifying paintings by certain artists. Now let's go a step further and incorporate the model's intelligence into an app.</p>
<p><a name="Exercise5"></a></p>
<h2>Exercise 5: Create a Node.js app that uses the model</h2>
<p>The true power of the Microsoft Custom Vision Service is the ease with which developers can incorporate its intelligence into their own applications using the <a href="https://southcentralus.dev.cognitive.microsoft.com/docs/services/eb68250e4e954d9bae0c2650db79c653/operations/58acd3c1ef062f0344a42814" rel="nofollow">Custom Vision Prediction API</a>. In this exercise, you will use Visual Studio Code to modify an app named Artwork to use the model you built and trained in previous exercises.</p>
<ol>
<li>
<p>If Node.js isn't installed on your system, go to <a href="https://nodejs.org" rel="nofollow">https://nodejs.org</a> and install the latest LTS version for your operating system.</p>
<blockquote>
<p>If you aren't sure whether Node.js is installed, open a Command Prompt or terminal window and type <strong>node -v</strong>. If you don't see a Node.js version number, then Node.js isn't installed. If a version of Node.js older than 6.0 is installed, it is highly recommend that you download and install the latest version.</p>
</blockquote>
</li>
<li>
<p>If Visual Studio Code isn't installed on your workstation, go to <a href="http://code.visualstudio.com" rel="nofollow">http://code.visualstudio.com</a> and install it now.</p>
</li>
<li>
<p>Start Visual Studio Code and select <strong>Open Folder...</strong> from the <strong>File</strong> menu. In the ensuing dialog, select the "Client\Artworks" folder included in the lab resources.</p>
<p><a href="Images/fe-select-folder.png" target="_blank"><img src="Images/fe-select-folder.png" alt="Selecting the Artworks folder" style="max-width:100%;"></a></p>
<p><em>Selecting the Artworks folder</em></p>
</li>
<li>
<p>Use the <strong>View</strong> &gt; <strong>Integrated Terminal</strong> command to open an integrated terminal window in Visual Studio Code. Then execute the following command in the integrated terminal to load the packages required by the app:</p>
<pre><code>npm install
</code></pre>
</li>
<li>
<p>Return to the Artwork project in the Custom Vision Service portal, click <strong>Performance</strong>, and then click <strong>Make default</strong> to make sure the latest iteration of the model is the default iteration.</p>
<p><a href="Images/portal-make-default.png" target="_blank"><img src="Images/portal-make-default.png" alt="Specifying the default iteration" style="max-width:100%;"></a></p>
<p><em>Specifying the default iteration</em></p>
</li>
<li>
<p>Before you can run the app and use it to call the Custom Vision Service, it must be modified to include endpoint and authorization information. To that end, click <strong>Prediction URL</strong>.</p>
<p><a href="Images/portal-prediction-url.png" target="_blank"><img src="Images/portal-prediction-url.png" alt="Viewing Prediction URL information" style="max-width:100%;"></a></p>
<p><em>Viewing Prediction URL information</em></p>
</li>
<li>
<p>The ensuing dialog lists two URLs: one for uploading images via URL, and another for uploading local images. Copy the Prediction API URL for image files to the clipboard.</p>
<p><a href="Images/copy-prediction-url.png" target="_blank"><img src="Images/copy-prediction-url.png" alt="Copying the Prediction API URL" style="max-width:100%;"></a></p>
<p><em>Copying the Prediction API URL</em></p>
</li>
<li>
<p>Return to Visual Studio Code and click <strong>predict.js</strong> to open it in the code editor.</p>
<p><a href="Images/vs-predict-file.png" target="_blank"><img src="Images/vs-predict-file.png" alt="Opening predict.js" style="max-width:100%;"></a></p>
<p><em>Opening predict.js</em></p>
</li>
<li>
<p>Replace "PREDICTION_ENDPOINT" in line 3 with the URL on the clipboard.</p>
<p><a href="Images/vs-prediction-endpoint.png" target="_blank"><img src="Images/vs-prediction-endpoint.png" alt="Adding the Prediction API URL" style="max-width:100%;"></a></p>
<p><em>Adding the Prediction API URL</em></p>
</li>
<li>
<p>Return to the Custom Vision Service portal and copy the Prediction API key to the clipboard.</p>
<p><a href="Images/copy-prediction-key.png" target="_blank"><img src="Images/copy-prediction-key.png" alt="Copying the Prediction API key" style="max-width:100%;"></a></p>
<p><em>Copying the Prediction API key</em></p>
</li>
<li>
<p>Return to Visual Studio Code and replace "PREDICTION_KEY" in line 4 of <strong>predict.js</strong> with the API key on the clipboard.</p>
<p><a href="Images/vs-prediction-key.png" target="_blank"><img src="Images/vs-prediction-key.png" alt="Adding the Prediction API key" style="max-width:100%;"></a></p>
<p><em>Adding the Prediction API key</em></p>
</li>
<li>
<p>Scroll down in <strong>predict.js</strong> and examine the block of code that begins on line 34. This is the code that calls out to the Custom Vision Service using AJAX. Using the Custom Vision Prediction API is as easy as making a simple, authenticated POST to a REST endpoint.</p>
<p><a href="Images/vs-code-block.png" target="_blank"><img src="Images/vs-code-block.png" alt="Making a call to the Prediction API" style="max-width:100%;"></a></p>
<p><em>Making a call to the Prediction API</em></p>
</li>
<li>
<p>Return to the integrated terminal in Visual Studio Code and execute the following command to start the app:</p>
<pre><code>npm start
</code></pre>
</li>
<li>
<p>Confirm that the Artworks app starts and displays a window like this one:</p>
<p><a href="Images/app-startup.png" target="_blank"><img src="Images/app-startup.png" alt="The Artworks app" style="max-width:100%;"></a></p>
<p><em>The Artworks app</em></p>
</li>
</ol>
<p>Artworks is a cross-platform app written with Node.js and <a href="https://electron.atom.io/" rel="nofollow">Electron</a>. As such, it is equally capable of running on Windows, macOS, and Linux. In the next exercise, you will use it to classify images by the artists who painted them.</p>
<p><a name="Exercise6"></a></p>
<h2>Exercise 6: Use the app to classify images</h2>
<p>In this exercise, you will use the Artworks app to submit images to the Custom Vision Service for classification. The app uses the JSON information returned from calls to the Custom Vision Prediction API's <a href="https://southcentralus.dev.cognitive.microsoft.com/docs/services/eb68250e4e954d9bae0c2650db79c653/operations/58acd3c1ef062f0344a42814" rel="nofollow">PredictImage</a> method to tell you whether an image represents a painting by Picasso, Rembrandt, Pollock, or none of the above. It also shows the probability that the classification assigned to the image is correct.</p>
<ol>
<li>
<p>Click the <strong>Browse (...)</strong> button in the Artworks app.</p>
<p><a href="Images/app-click-browse.png" target="_blank"><img src="Images/app-click-browse.png" alt="Browsing for local images in the Artworks app" style="max-width:100%;"></a></p>
<p><em>Browsing for local images in the Artworks app</em></p>
</li>
<li>
<p>Browse to the "Quick Tests" folder in the lab resources. Select the file named <strong>PicassoTest_02.jpg</strong>, and then click <strong>Open</strong>.</p>
</li>
<li>
<p>Click the <strong>Predict</strong> button to submit the image to the Custom Vision Service.</p>
<p><a href="Images/app-click-predict.png" target="_blank"><img src="Images/app-click-predict.png" alt="Submitting the image to the Custom Vision Service" style="max-width:100%;"></a></p>
<p><em>Submitting the image to the Custom Vision Service</em></p>
</li>
<li>
<p>Confirm that the app identifies the painting as a Picasso.</p>
<p><a href="Images/app-prediction-01.png" target="_blank"><img src="Images/app-prediction-01.png" alt="Classifying an image as a Picasso" style="max-width:100%;"></a></p>
<p><em>Classifying an image as a Picasso</em></p>
</li>
<li>
<p>Repeat steps 1 through 3 for <strong>RembrandtTest_01.jpg</strong> and <strong>PollockTest_01.jpg</strong> and confirm that the app can identify paintings by Rembrandt and Pollock.</p>
<p><a href="Images/app-prediction-02.png" target="_blank"><img src="Images/app-prediction-02.png" alt="Classifying an image as a Rembrandt" style="max-width:100%;"></a></p>
<p><em>Classifying an image as a Rembrandt</em></p>
</li>
<li>
<p>Repeat steps 1 through 3 for <strong>VanGoghTest_01.png</strong> and <strong>VanGoghTest_02.png</strong> and confirm that the app does not identify these Van Gogh masterworks as paintings by Picasso, Rembrandt, or Pollock.</p>
<p><a href="Images/app-prediction-03.png" target="_blank"><img src="Images/app-prediction-03.png" alt="Not a Picasso, Rembrandt, or Pollock" style="max-width:100%;"></a></p>
<p><em>Not a Picasso, Rembrandt, or Pollock</em></p>
</li>
<li>
<p>As you can see, using the Prediction API from an app is just as reliable as through the Custom Vision Service portal — and way more fun! What's more, if you go to the Predictions page in the portal, you'll find that each of the images uploaded via the app is shown there as well.</p>
<p><a href="Images/portal-all-predictions.png" target="_blank"><img src="Images/portal-all-predictions.png" alt="Images submitted to the Custom Vision Service" style="max-width:100%;"></a></p>
<p><em>Images submitted to the Custom Vision Service</em></p>
</li>
</ol>
<p>Feel free to test with images of your own and gauge the model's adeptness at identifying artists or determining that an image is not a Picasso, Rembrandt, or Pollock. If you'd like to train it to recognize Van Goghs, too, simply upload some Van Gogh paintings, tag them with "Van Gogh," and retrain the model. There is no limit to the intelligence you can add if you're willing to do the training. And remember that in general, the more images you train with, the smarter the model will be.</p>
<p><a name="Summary"></a></p>
<h2>Summary</h2>
<p>Image classification is playing an increasingly large role in industry as a means for automating such tasks as checking images uploaded to Web sites for offensive content and inspecting parts rolling off of assembly lines for defects. Building an image-classification model manually — that is, coding it from the ground up in Python, R, or another language — requires no small amount of expertise, but the Custom Vision Service enables virtually anyone to build sophisticated image-classification models. And once a model is built and trained, an app that uses it is only few lines of code away.</p>
<hr>
<p>Copyright 2017 Microsoft Corporation. All rights reserved. Except where otherwise noted, these materials are licensed under the terms of the MIT License. You may use them according to the license as is most appropriate for your project. The terms of this license can be found at <a href="https://opensource.org/licenses/MIT" rel="nofollow">https://opensource.org/licenses/MIT</a>.</p>
</body>
</html>
<!-- This document was created with MarkdownPad, the Markdown editor for Windows (http://markdownpad.com) -->
